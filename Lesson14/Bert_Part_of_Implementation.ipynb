{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Process\n",
        "\n",
        "- NSP\n",
        "- MLM\n",
        "- BERTDataset\n",
        "- getPair()\n",
        "- mask_sentence()\n",
        "- getItem()"
      ],
      "metadata": {
        "id": "_6UXIWg26nyn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN2WAwD-4sTm"
      },
      "outputs": [],
      "source": [
        "from  torch.utils.data import Dataset, Dataloader\n",
        "import random\n",
        "import torch\n",
        "\n",
        "class BERTDataset(Dataset):\n",
        "  def __init__(self, conv_pairs, toknizer, seq_len):\n",
        "    self.conv_pairs = conv_pairs\n",
        "    self.toknizer = toknizer\n",
        "    self.seq_len = seq_len\n",
        "    self.num_pairs = len(conv_pairs)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.num_pairs\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    s1,s2, is_next = self.conv_pairs[idx]\n",
        "    masked_numericalized_s1,s1_mask = self.mask_sentence(s1)\n",
        "    masked_numericalized_s2,s2_mask = self.mask_sentence(s2)\n",
        "\n",
        "    t1 = [self.toknizer.vocab['[CLS]']] + masked_numericalized_s1 + [self.toknizer['[SEP]']]\n",
        "    t2 = [self.toknizer.vocab['[CLS]']] + masked_numericalized_s2 + [self.toknizer['[SEP]']]\n",
        "    t1_mask = [self.tokenizer.vocab['[PAD]']] + s1_mask + [self.tokenizer.vocab['[PAD]']]\n",
        "    t2_mask = s2_mask + [self.tokenizer.vocab['[PAD]']]\n",
        "\n",
        "    segment_ids = ([1 for _in range(len(t1))]) + [2 for _ in range(len(t2))][:self.seq_len]\n",
        "    bert_input = (t1 + t2)[:self.seq_len]\n",
        "    bert_label = (t1_mask + t2_mask)[:self.seq_len]\n",
        "    padding = [self.toknizer.vocab['[PAD]']]for _ in range(self.seq_len - len(bert_input))\n",
        "    bert_input.extend(padding),bert_label.exntend(padding),segment_ids.extend(padding)\n",
        "\n",
        "    output = {\n",
        "        \"bert_input\": torch.tensor(bert_input),\n",
        "        \"bert_label\": torch.tensor(bert_label),\n",
        "        \"segment_ids\": torch.tensor(segment_ids),\n",
        "        \"is_next\": torch.tensor(is_next)\n",
        "    }\n",
        "    return {key: value for key, value in output.items()}\n",
        "\n",
        "  def get_pair(self, index):\n",
        "    s1, s2 = self.conv_pairs[index]\n",
        "    return s1,s2\n",
        "    is_next = 1\n",
        "    if random.random() > 0.5\n",
        "      randon_index = ranbdom.randrange(len(self.conv_pairs))\n",
        "      s2 = self.conv_pairs[randon_index][1]\n",
        "      is_next = 0\n",
        "    return s1,s2,is_next\n",
        "\n",
        "  def mask_sentence(self,s):\n",
        "    words = s.split()\n",
        "    masked_numericalized_s = []\n",
        "    mask = []\n",
        "    for word in words:\n",
        "      prob = random.random()\n",
        "      token_ids = self.tokenizer(word)['input_ids'][1:-1]\n",
        "      if prob < 0.15:\n",
        "        prob /= 0.15\n",
        "        for token_id in token_ids:\n",
        "          if prob < 0.8:\n",
        "            masked_numericalized_s.append(self.tokenizer.vocab['[MASK]'])\n",
        "          else if prob < 0.9:\n",
        "            masked_numericalized_s.append(random.randrange(len(self.tokenizer.vocab)))\n",
        "          else:\n",
        "            masked_numericalized_s.append(token_id)\n",
        "          mask.append(1)\n",
        "      else:\n",
        "        masked_numericalized_s.extend(token_ids)\n",
        "        mask.extend([0] * len(token_ids))\n",
        "\n",
        "    assert len(masked_numericalized_s) == len(mask)\n",
        "    return masked_numericalized_s,mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert Input Embeddings\n",
        "\n",
        "- token embedding\n",
        "- segment embedding\n",
        "- positional embedding\n",
        "\n",
        "embeddings = token_embeddings  + segment_embeddings +  positional_embeddingd"
      ],
      "metadata": {
        "id": "c7OWre6h_lpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(torch.nn.Module):\n",
        "  def __init__(self,d_model.seq_len=128):\n",
        "    super().__init__()\n",
        "    pe = torch.zeors(seq_len,d_model)\n",
        "    pe.requires_grad = False\n",
        "    for pos in range(seq_len):\n",
        "      for i in range(0,d_model,2):\n",
        "        pe[pos,i] = math.sin(pos/10000**(2*i/d_model))\n",
        "        pe[pos,i+1] = math.cos(pos/10000**(2*i/d_model))\n",
        "    pe = pe.unsqueeze(0)\n",
        "\n",
        "    self.register_buffer('pe',pe)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.pe[:,:x.size(1)] + x\n",
        "\n",
        "class BERTEmbeddings(torch.nn.Module):\n",
        "  def __init__(self, vocab_size, d_model, seq_len=64):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.seq_ken = seq_len\n",
        "    self.token_embeddings = torch.nn.Embedding(vocab_size, d_model)\n",
        "    self.segment_embedding = torch.nn.Embedding(3,d_model, padding_index)\n",
        "    self.position_embedding = PositionalEncoding(d_model, seq_len)\n",
        "    self.droupout = torch.nn.Dropout(p=0.1)\n",
        "\n",
        "  def forward(self, input_ids, segment_ids):\n",
        "    token_embeddings = self.token_embeddings(input_ids)\n",
        "    segment_embeddings = self.segment_embedding(segment_ids)\n",
        "    embeddings = token_embeddings + segment_embeddings\n",
        "\n",
        "    embeddings = token_embeddings + segment_embeddings + positional_embedding\n",
        "    embeddings = self.droupout(embeddings)\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "1I8G2yENACRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi_Head_Attention\n"
      ],
      "metadata": {
        "id": "fBjKmaQEBzR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttentionBlock(nn.Module):\n",
        "  def __init__(self,d_model,num_heads,dropout):\n",
        "    super().__init__()\n",
        "    self.embed_dim = d_model\n",
        "    self.num_heads = num_heads\n",
        "    assert d_model % num_heads == 0\n",
        "    self.d_k = d_model // num_heads\n",
        "\n",
        "    self.q_linear = nn.Linear(d_model, d_model)\n",
        "    self.k_linear = nn.Linear(d_model, d_model)\n",
        "    self.v_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "    self.o_linear = nn.Linear(d_model, d_model)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,q,k,v, mask=None):\n",
        "    q_transformed = self.q_linear(q)\n",
        "    k_transformed = self.k_linear(k)\n",
        "    v_transformed = self.v_linear(v)\n",
        "\n",
        "    q_transformed = q_transformed.view(q_transformed.shap[0],q_transformed.shape[1], self.num_heads, self.d_k).transpose(1,2)\n",
        "    k_transformed = k_transformed.view(k_transformed.shap[0],k_transformed.shape[1], self.num_heads, self.d_k).transpose(1,2)\n",
        "    v_transformed = v_transformed.view(v_transformed.shap[0],v_transformed.shape[1], self.num_heads, self.d_k).transpose(1,2)\n",
        "\n",
        "    scaled_attn_scores = torch.matul(q_transformed, k_transformed.transpose(-2,-1)) / math.sqrt(self.d_k)\n",
        "    saled_attn_scores.masked_fill_(mask == 0, -1e9)\n",
        "    attn_weights = torch.softmax(scaled_attn_scores, dim=-1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "    z = attn_weights @ v_transformed\n",
        "\n",
        "    z = z.transpose(1,2).contiguous().view(z.shape[0],-1,self.num_heads * self.d_k)\n",
        "    z = self.o_linear(z)\n",
        "    return z"
      ],
      "metadata": {
        "id": "3EY_4luXB7sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FFNN BLOCK"
      ],
      "metadata": {
        "id": "gceYBU2-DrgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardBlock(nn.Module):\n",
        "  def __init__(self, d_model, dim_feedforward, drop_out_p):\n",
        "    super().__init__()\n",
        "    self.embed_dim = d_model\n",
        "    self.dim_feedforward = dim_feedforward\n",
        "\n",
        "    self.fc1= nn.linear(d_model, dim_feedforward)\n",
        "    self.fc2 = nn.linear(dim_feedforward, d_model)\n",
        "    self.dropout = nn.Dropout(drop_out_p)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.fc2(self.dropout(torch.relu(self.fc1(x))))"
      ],
      "metadata": {
        "id": "016qRbxWDw_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Residual Connection & Add&Norm"
      ],
      "metadata": {
        "id": "r6z_PqOKEc4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualConnection(nn.Module):\n",
        "  def __init__(self,d_model,drop_out_p):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(drop_out_p)\n",
        "    self.layernorm = torch.nn.layerNorm(d_model)\n",
        "\n",
        "  def forward(self, x, sublayer):\n",
        "    return x + self.dropout((self.layernorm(sublayer(x)))"
      ],
      "metadata": {
        "id": "nvvp-d_UEm9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder Block"
      ],
      "metadata": {
        "id": "8I-WQrIEFMMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self, d_model, num_heads, dim_feedforward, dropout):\n",
        "    super().__init__()\n",
        "    self.self_attention_block = MultiHeadAttentionBlock(d_model, num_heads, dropout)\n",
        "    self.feed_forward_block = FeedForwardBlock(d_model, dim_feedforward, dropout)\n",
        "    self.residual_connection = nn.Modulelist([ResidualConnection(d_model, dropout) for _ in range(2)])\n",
        "\n",
        "  def forward(self,x, mask):\n",
        "    x = self.residual_connection[0](x, lambda x: self.self_attention_block(x,x,x,mask))\n",
        "    x = self.residual_connection[1](x, self.feed_forward_block)\n",
        "    return x"
      ],
      "metadata": {
        "id": "-7J_-_1JFR8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Block\n"
      ],
      "metadata": {
        "id": "84KoglKZF2mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, vocab_size,d_model, num_heads,dim_feedforward, dropout,num_encoder_blocks =6, seq_len):\n",
        "    super(Transformer, self).__init__()\n",
        "    slef.src_embed = BERTEmbedding(vocab_size, d_model, seq_len=seq_len)\n",
        "    encoder_blocks = []\n",
        "    for _ in range(num_encoder_blocks):\n",
        "      encoder_blocks.append(EncoderBlock(d_model, num_heads, dim_feedforward, dropout))\n",
        "\n",
        "  def encode(self,x,segment_ids):\n",
        "    mask = (x>0).unqueeze(1).repeat(1,x.size(1),1).unsqueeze(1)\n",
        "    x = self.src_embed(x,segment_ids)\n",
        "    for encoder_block in self.encoder_blocks:\n",
        "      x = encoder_block(x,mask)\n",
        "    return x"
      ],
      "metadata": {
        "id": "A_WBKgeuF6L9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformr = Transformer(len(tokenizer, vocab))\n",
        "bert_result = transformer(sample_data['whatever'],sample_data['segment_label'])\n",
        "print(bert_result.size())"
      ],
      "metadata": {
        "id": "4vdVl2EOG4Mo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}