{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuwFPlWm9-Sj",
        "outputId": "64372406-ca75-4f5b-ec0d-8b09c14ee137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2416, 0.1069],\n",
            "        [0.3111, 0.1202],\n",
            "        [0.0182, 0.0249]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "linear = nn.Linear(32,2)\n",
        "inputs = torch.rand(3,32)\n",
        "\n",
        "outputs = linear(inputs)\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import functional as F\n",
        "activation = F.sigmoid(outputs)\n",
        "print(activation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ-PArdfAU6V",
        "outputId": "48694d86-21b7-4dc8-dd6f-95ada6f3d9d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5601, 0.5267],\n",
            "        [0.5772, 0.5300],\n",
            "        [0.5046, 0.5062]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activation = F.softmax(outputs,dim=1)\n",
        "print(activation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKnnwHUiA6Ar",
        "outputId": "9a30192a-e703-4f1a-c061-e858791e12f9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5336, 0.4664],\n",
            "        [0.5476, 0.4524],\n",
            "        [0.4983, 0.5017]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activation = F.relu(outputs)\n",
        "print(activation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz4hZ09TBEuF",
        "outputId": "a7078a83-bc29-47fe-ffa5-578187ac1dab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2416, 0.1069],\n",
            "        [0.3111, 0.1202],\n",
            "        [0.0182, 0.0249]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 自定义神经网络模型"
      ],
      "metadata": {
        "id": "D_uaU-lNBMFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import torch\n",
        " from torch import nn\n",
        " from torch.nn import functional as F\n",
        "\n",
        " class MLP(nn.Module):\n",
        "  def __init__(self,input_dim,hidden_dim,num_class):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
        "    self.activate = F.relu\n",
        "    self.linear2 = nn.Linear(hidden_dim, num_class)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    hidden = self.linear1(inputs)\n",
        "    activation = self.activate(hidden)\n",
        "    outputs =self.linear2(activation)\n",
        "    probs = F.softmax(outputs, dim=1)\n",
        "    return probs\n",
        "\n",
        "mlp = MLP(input_dim=4,hidden_dim=5, num_class=2)\n",
        "inputs = torch.rand(3,4)\n",
        "probs = mlp(inputs)\n",
        "print(probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjHAsDyVBJP1",
        "outputId": "9b5847a2-51ba-4ec6-9a51-4759679b6267"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3804, 0.6196],\n",
            "        [0.4273, 0.5727],\n",
            "        [0.3861, 0.6139]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 卷积神经网络"
      ],
      "metadata": {
        "id": "vfoQpkklIS-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Conv1d\n",
        "\n",
        "conv1 = Conv1d(5,2,4)\n",
        "conv2 = Conv1d(5,2,3)\n",
        "\n",
        "inputs = torch.rand(2,5,6)\n",
        "\n",
        "outputs1 = conv1(inputs)\n",
        "outputs2 = conv2(inputs)\n",
        "\n",
        "print(outputs1)\n",
        "print(outputs2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhHLXm31DYW3",
        "outputId": "8178a7c4-6cf2-4606-e9e7-43594e0fdfb8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0576,  0.1622, -0.2234],\n",
            "         [-0.2325, -0.3413, -0.2250]],\n",
            "\n",
            "        [[-0.3782, -0.1242, -0.1772],\n",
            "         [-0.2281, -0.3157, -0.2179]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[ 0.6040,  0.5271,  0.7065,  0.5967],\n",
            "         [-0.1372, -0.2387, -0.4239, -0.2224]],\n",
            "\n",
            "        [[ 0.6710,  0.5483,  0.5937,  0.5187],\n",
            "         [-0.3526, -0.2052, -0.3864, -0.3359]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import MaxPool1d\n",
        "\n",
        "pool1 = MaxPool1d(3)\n",
        "pool2 = MaxPool1d(4)\n",
        "\n",
        "outputs1_pool1 = pool1(outputs1)\n",
        "print(outputs1_pool1)\n",
        "\n",
        "outputs2_pool2 = pool2(outputs2)\n",
        "print(outputs2_pool2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkKpw1bFIvH9",
        "outputId": "2ca37412-7c1f-4dce-fac1-6a39a3591bbc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.1622],\n",
            "         [-0.2250]],\n",
            "\n",
            "        [[-0.1242],\n",
            "         [-0.2179]]], grad_fn=<SqueezeBackward1>)\n",
            "tensor([[[ 0.7065],\n",
            "         [-0.1372]],\n",
            "\n",
            "        [[ 0.6710],\n",
            "         [-0.2052]]], grad_fn=<SqueezeBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "outputs_pool1 = F.max_pool1d(outputs1, kernel_size=outputs1.shape[2])\n",
        "print(outputs1_pool1)\n",
        "\n",
        "outputs_pool2 = F.max_pool1d(outputs2, kernel_size=outputs2.shape[2])\n",
        "print(outputs_pool2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgO2yPBuLNIO",
        "outputId": "b892d0e3-797f-423b-cd6e-e8d9843ec0e5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.1622],\n",
            "         [-0.2250]],\n",
            "\n",
            "        [[-0.1242],\n",
            "         [-0.2179]]], grad_fn=<SqueezeBackward1>)\n",
            "tensor([[[ 0.7065],\n",
            "         [-0.1372]],\n",
            "\n",
            "        [[ 0.6710],\n",
            "         [-0.2052]]], grad_fn=<SqueezeBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_pool_squeeze1 = outputs_pool1.squeeze(dim=2)\n",
        "print(outputs_pool_squeeze1)\n",
        "\n",
        "outputs_pool_squeeze2 = outputs_pool2.squeeze(dim=2)\n",
        "print(outputs_pool_squeeze2)\n",
        "\n",
        "outputs_pool = torch.cat([outputs_pool_squeeze1,outputs_pool_squeeze2],dim=1)\n",
        "\n",
        "print(outputs_pool)\n",
        "\n",
        "from torch.nn import Linear\n",
        "\n",
        "linear = Linear(4,2)\n",
        "outputs_linear=linear(outputs_pool)\n",
        "print(outputs_linear)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdEZglvULo6g",
        "outputId": "a4f63aa2-cd2e-4e91-9400-5a926f987dd7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1622, -0.2250],\n",
            "        [-0.1242, -0.2179]], grad_fn=<SqueezeBackward1>)\n",
            "tensor([[ 0.7065, -0.1372],\n",
            "        [ 0.6710, -0.2052]], grad_fn=<SqueezeBackward1>)\n",
            "tensor([[ 0.1622, -0.2250,  0.7065, -0.1372],\n",
            "        [-0.1242, -0.2179,  0.6710, -0.2052]], grad_fn=<CatBackward0>)\n",
            "tensor([[ 0.2137, -0.3520],\n",
            "        [ 0.3050, -0.3732]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 循环神经网络"
      ],
      "metadata": {
        "id": "mDcKced1NA71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import RNN\n",
        "rnn = RNN(input_size=4, hidden_size=5,batch_first=True)\n",
        "\n",
        "inputs = torch.rand(2,3,4)\n",
        "\n",
        "outputs, hn = rnn(inputs)\n",
        "\n",
        "print(outputs)\n",
        "\n",
        "print(hn)\n",
        "\n",
        "print(outputs.shape, hn.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFojBFWuM_4q",
        "outputId": "ffbf2368-8aaa-4682-add6-decb2cfa5c3e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.1793, -0.0988,  0.7587, -0.0575, -0.7716],\n",
            "         [-0.0714,  0.0189,  0.7073, -0.3451, -0.6584],\n",
            "         [ 0.1919, -0.2825,  0.7780, -0.5581, -0.8399]],\n",
            "\n",
            "        [[ 0.1646, -0.2326,  0.7935, -0.1408, -0.7047],\n",
            "         [ 0.3552, -0.3788,  0.7323, -0.2776, -0.5805],\n",
            "         [ 0.1527, -0.4057,  0.8812, -0.4943, -0.7798]]],\n",
            "       grad_fn=<TransposeBackward1>)\n",
            "tensor([[[ 0.1919, -0.2825,  0.7780, -0.5581, -0.8399],\n",
            "         [ 0.1527, -0.4057,  0.8812, -0.4943, -0.7798]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "torch.Size([2, 3, 5]) torch.Size([1, 2, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import LSTM\n",
        "lstm = LSTM(input_size=4, hidden_size=5, batch_first=True)\n",
        "inputs = torch.rand(2,3,4)\n",
        "\n",
        "outputs, (hn,cn) = lstm(inputs)\n",
        "\n",
        "print(outputs)\n",
        "\n",
        "print(hn)\n",
        "\n",
        "print(cn)\n",
        "\n",
        "print(outputs.shape, hn.shape, cn.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzAr11iJOUCT",
        "outputId": "a86f92c4-4208-43d2-b0f1-2f3ee17eff73"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.1271,  0.1416, -0.1430,  0.0548, -0.0897],\n",
            "         [-0.2134,  0.1865, -0.2268,  0.1111, -0.1690],\n",
            "         [-0.3167,  0.2016, -0.1689, -0.0131, -0.2028]],\n",
            "\n",
            "        [[-0.1477,  0.1590, -0.0769,  0.0089, -0.0942],\n",
            "         [-0.1774,  0.1872, -0.1744,  0.1229, -0.1311],\n",
            "         [-0.2850,  0.1583, -0.2635,  0.0719, -0.1983]]],\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "tensor([[[-0.3167,  0.2016, -0.1689, -0.0131, -0.2028],\n",
            "         [-0.2850,  0.1583, -0.2635,  0.0719, -0.1983]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "tensor([[[-0.6079,  0.3925, -0.3893, -0.0209, -0.3846],\n",
            "         [-0.5163,  0.2950, -0.5286,  0.1134, -0.4858]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "torch.Size([2, 3, 5]) torch.Size([1, 2, 5]) torch.Size([1, 2, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Transformer"
      ],
      "metadata": {
        "id": "FRIMFpF0Q9su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_layer = nn.TransformerEncoderLayer(d_model=4,nhead=2)\n",
        "src = torch.rand(2,3,4)\n",
        "\n",
        "out = encoder_layer(src)\n",
        "\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUM6MRdVQ_rp",
        "outputId": "46d9fe3e-0abd-490a-cb07-8f3b51d76663"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.8180, -1.5911, -0.1137,  0.8867],\n",
            "         [ 0.5552, -0.5168, -1.3276,  1.2892],\n",
            "         [ 0.2924, -1.7016,  0.5902,  0.8189]],\n",
            "\n",
            "        [[ 0.3458, -1.7152,  0.6658,  0.7037],\n",
            "         [ 1.2341, -1.4354,  0.5457, -0.3444],\n",
            "         [-1.5780, -0.1026,  1.0490,  0.6316]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
        "out = transformer_encoder(src)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isYlpz-qSDmL",
        "outputId": "ff97dec3-2750-4ce8-c206-01db6eeb2b61"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.7625, -1.4378, -0.4118,  1.0871],\n",
            "         [ 0.1225, -1.3796, -0.1751,  1.4321],\n",
            "         [ 0.7397, -1.6816,  0.7723,  0.1696]],\n",
            "\n",
            "        [[ 0.8837, -1.6951,  0.3153,  0.4962],\n",
            "         [ 1.1933, -1.2132,  0.7528, -0.7329],\n",
            "         [-1.0754, -0.9211,  1.0312,  0.9653]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = transformer_encoder(src)\n",
        "decoder_layer = nn.TransformerDecoderLayer(d_model=4, nhead=2)\n",
        "transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
        "out_part = torch.rand(2,3,4)\n",
        "out = transformer_decoder(out_part, memory)\n",
        "\n",
        "print(out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5rLhZIjSOnO",
        "outputId": "ee7364e4-cdba-462a-ae82-6900b7cf2d3a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.2979,  0.5342,  1.2231, -1.4594],\n",
            "         [ 0.1066, -1.5431,  0.1818,  1.2547],\n",
            "         [-0.3130,  0.8409,  0.9720, -1.5000]],\n",
            "\n",
            "        [[-0.9633,  0.3224,  1.4958, -0.8548],\n",
            "         [ 1.3743, -1.2874,  0.4309, -0.5179],\n",
            "         [-0.1883,  0.4357,  1.2445, -1.4919]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 梯度下降的训练实战"
      ],
      "metadata": {
        "id": "ezmpqWgxUZOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn,optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self,input_dim,hidden_dim,num_class):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
        "    self.activate = F.relu\n",
        "    self.linear2 = nn.Linear(hidden_dim, num_class)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    hidden = self.linear1(inputs)\n",
        "    activation = self.activate(hidden)\n",
        "    outputs =self.linear2(activation)\n",
        "    log_probs = F.log_softmax(outputs, dim=1)\n",
        "    return log_probs\n",
        "\n",
        "x_train = torch.tensor([[0.0,0.0],[0.0,1.0],[1.0,0.0],[1.0,1.0]])\n",
        "y_train = torch.tensor([0,1,1,0])\n",
        "\n",
        "model = MLP(input_dim = 2, hidden_dim = 5, num_class = 2)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
        "\n",
        "for epoch in range(500):\n",
        "  y_pred = model(x_train)\n",
        "  loss = criterion(y_pred, y_train)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print('Parameters:')\n",
        "for name, param in model.named_parameters():\n",
        "  print(name, param.data)\n",
        "\n",
        "y_pred = model(x_train)\n",
        "print('Predicted results:', y_pred.argmax(axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FipiKF2wUY1x",
        "outputId": "8fa537aa-0fb4-4cd5-c82f-a3af3b7bc055"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters:\n",
            "linear1.weight tensor([[ 1.2419, -1.2401],\n",
            "        [ 1.0910,  1.0778],\n",
            "        [-0.1706,  0.8729],\n",
            "        [-0.2930, -0.2859],\n",
            "        [-0.1691, -0.3952]])\n",
            "linear1.bias tensor([ 8.9211e-04, -1.0896e+00,  3.9133e-01, -5.9601e-01, -3.8474e-01])\n",
            "linear2.weight tensor([[-1.0757,  1.3517, -0.6965, -0.3069, -0.2496],\n",
            "        [ 1.1203, -1.0164,  0.2546, -0.2340, -0.2441]])\n",
            "linear2.bias tensor([ 0.2727, -0.3108])\n",
            "Predicted results: tensor([0, 1, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PJVHpKFvS6-o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}